# Helper methods that pertain to the spreadsheet bulk metadata upload routines.
module SpreadsheetHelper

  # List the messages that we're going to display to the end user
  @@user_messages = Set.new [ 'argo.bulk_metadata.bulk_log_job_start',
                              'argo.bulk_metadata.bulk_log_job_complete',
                              'argo.bulk_metadata.bulk_log_job_save_success',
                              'argo.bulk_metadata.bulk_log_apo_fail',
                              'argo.bulk_metadata.bulk_log_not_exist',
                              'argo.bulk_metadata.bulk_log_note',
                              'argo.bulk_metadata.bulk_log_record_count',
                              'argo.bulk_metadata.bulk_log_error_exception',
                              'argo.bulk_metadata.bulk_log_invalid_column',
                              'argo.bulk_metadata.bulk_log_skipped_mods',
                              'argo.bulk_metadata.bulk_log_skipped_accession',
                              'argo.bulk_metadata.bulk_log_skipped_not_accessioned',
                              'argo.bulk_metadata.bulk_log_no_connection',
                              'argo.bulk_metadata.bulk_log_invalid_url',
                              'argo.bulk_metadata.bulk_log_nonexistent_file',
                              'argo.bulk_metadata.bulk_log_invalid_permission',
                              'argo.bulk_metadata.bulk_log_druids_loaded',
                              'argo.bulk_metadata.bulk_log_internal_error',
                              'argo.bulk_metadata.bulk_log_unable_to_version']

  # List the subset of messages that indicate an error with the job
  @@error_messages = Set.new ['argo.bulk_metadata.bulk_log_apo_fail',
                              'argo.bulk_metadata.bulk_log_not_exist',
                              'argo.bulk_metadata.bulk_log_error_exception',
                              'argo.bulk_metadata.bulk_log_invalid_column',
                              'argo.bulk_metadata.bulk_log_no_connection',
                              'argo.bulk_metadata.bulk_log_invalid_url',
                              'argo.bulk_metadata.bulk_log_nonexistent_file',
                              'argo.bulk_metadata.bulk_log_invalid_permission',
                              'argo.bulk_metadata.bulk_log_internal_error',
                              'argo.bulk_metadata.bulk_log_unable_to_version']

  # Creates an array of user friendly log messages from the bulk upload log.
  #
  # @param  [String]       apo                    The governing APO's druid
  # @param  [String]       job_output_directory   The bulk upload job output directory
  # @return [Array<Hash>]  An array where each element is a hash. The hash keys are strings defined in en.yml and the values are string messages.
  def load_user_log(apo, job_output_directory)
    log_items = []
    druids_loaded = 0

    # Each line in the log is assumed to be of the format "<keyword> <string>", where <keyword> is a phrase from
    # the en.yml file and <string> is a more informative message. Note that <string> may be empty for certain exceptions.
    File.open(File.join(job_output_directory, Argo::Config.bulk_metadata_log), 'r') { |log_file|
      log_file.each_line do |log_line|
        split_line = log_line.split(/\s+/, 2)

        # A few of the log messages are considered 'too technical' and will not be displayed
        next unless split_line.length > 0 && @@user_messages.include?(split_line[0])
        # Ignore lines that don't conform to the format
        current_hash = {}
        if split_line.length == 2
          druids_loaded += 1 if split_line[0] == 'argo.bulk_metadata.bulk_log_job_save_success'
          current_hash[split_line[0]] = split_line[1]
          log_items.push(current_hash)
        elsif split_line.length == 1
          current_hash[log_line.strip] = nil
          log_items.push(current_hash)
        end
      end
    }
    log_items.push({ 'argo.bulk_metadata.bulk_log_druids_loaded' => druids_loaded})
    log_items
  end

  # Creates a CSV file from the log messages generated by load_user_log. The CSV file is stored in the bulk
  # upload output directory.
  #
  # @param [Array<Hash>]  user_messages          The output array of hashes from load_user_log.
  # @param [String]       job_output_directory   The bulk upload job output directory
  # @return [Void]
  def user_log_csv(user_messages, job_output_directory)
    File.open(File.join(job_output_directory, Argo::Config.bulk_metadata_csv_log), 'w') { |csv_file|
      user_messages.each do |message|
        key = message.keys[0]

        if (@@user_messages.include?(key))
          csv_file.puts("\"#{I18n.t(key)}\",\"#{message[key]}\"")
        end
      end
    }
  end
end
